{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e0f1e2-73ae-4c8b-846a-cf589f65a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64365e8-d35c-4f91-8c18-4dbba877d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/splited/train/'\n",
    "test_dir = 'data/splited/test/'\n",
    "val_dir = 'data/splited/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b7636f-2665-4073-83cd-465d0af39c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_to_int = {}  # Dictionary to map labels to integers\n",
    "    int_label = 0  # Starting integer label\n",
    "    for label in os.listdir(directory):\n",
    "        label_to_int[label] = int_label\n",
    "        label_path = os.path.join(directory, label)\n",
    "        for image_file in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (224, 224))  # Resize if necessary\n",
    "            images.append(image)\n",
    "            labels.append(int_label)\n",
    "        int_label += 1\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad891d7-9165-4f93-ba48-bee1edea8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data(train_dir)\n",
    "X_test, y_test = load_data(test_dir)\n",
    "X_val, y_val = load_data(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d17935bf-4182-4c4f-a498-b20798e0c93e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 68.1 GiB for an array with shape (60745, 224, 224, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\n\u001b[0;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      3\u001b[0m X_val \u001b[38;5;241m=\u001b[39m X_val \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 68.1 GiB for an array with shape (60745, 224, 224, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_val = X_val / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75be2c57-7218-4c8d-b577-8b5ba97d21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e000c68e-1445-45ea-bc3d-1792140587d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a593dc52-5b4c-4007-bedb-28cccf238689",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "426ca4fe-23ec-407e-ba05-4c9064b14722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1899/1899 [==============================] - 1741s 915ms/step - loss: 1.9277 - accuracy: 0.6205 - val_loss: 0.8941 - val_accuracy: 0.7238\n",
      "Epoch 2/10\n",
      "1899/1899 [==============================] - 1778s 936ms/step - loss: 0.7539 - accuracy: 0.7605 - val_loss: 0.8600 - val_accuracy: 0.7445\n",
      "Epoch 3/10\n",
      "1899/1899 [==============================] - 1767s 931ms/step - loss: 0.5450 - accuracy: 0.8244 - val_loss: 0.8581 - val_accuracy: 0.7352\n",
      "Epoch 4/10\n",
      "1899/1899 [==============================] - 1764s 929ms/step - loss: 0.4009 - accuracy: 0.8694 - val_loss: 0.9249 - val_accuracy: 0.7318\n",
      "Epoch 5/10\n",
      "1899/1899 [==============================] - 1752s 922ms/step - loss: 0.3117 - accuracy: 0.8989 - val_loss: 1.0327 - val_accuracy: 0.7415\n",
      "Epoch 6/10\n",
      "1899/1899 [==============================] - 1747s 920ms/step - loss: 0.2462 - accuracy: 0.9215 - val_loss: 1.3463 - val_accuracy: 0.7337\n",
      "Epoch 7/10\n",
      "1899/1899 [==============================] - 1743s 918ms/step - loss: 0.2113 - accuracy: 0.9343 - val_loss: 1.2321 - val_accuracy: 0.7299\n",
      "Epoch 8/10\n",
      "1899/1899 [==============================] - 1738s 915ms/step - loss: 0.1825 - accuracy: 0.9433 - val_loss: 1.3158 - val_accuracy: 0.7331\n",
      "Epoch 9/10\n",
      "1899/1899 [==============================] - 1757s 925ms/step - loss: 0.1657 - accuracy: 0.9497 - val_loss: 1.3330 - val_accuracy: 0.7187\n",
      "Epoch 10/10\n",
      "1899/1899 [==============================] - 1805s 951ms/step - loss: 0.1651 - accuracy: 0.9519 - val_loss: 1.4498 - val_accuracy: 0.7267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22b6938fb10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adda9a57-e516-4d6b-9f9b-a98ba9e65232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 45s 200ms/step - loss: 1.8489 - accuracy: 0.7127\n",
      "Test Loss: 1.8488743305206299\n",
      "Test Accuracy: 0.7126596570014954\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6cb0713-9ad8-41d5-a534-77fc226c8b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\python\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('great_model_with_spectogram.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26f350b1-63f7-47eb-8ace-641d2b1f2dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: last layer is not SoftMax Activation\n"
     ]
    }
   ],
   "source": [
    "if isinstance(model.layers[-1], Activation) and model.layers[-1].activation == softmax:\n",
    "    model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)\n",
    "else:\n",
    "    print('Error: last layer is not SoftMax Activation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54ed0214-1a8d-46ca-b089-6174c72f35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qualia_codegen_core in c:\\programs\\python\\lib\\site-packages (2.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\programs\\python\\lib\\site-packages (from qualia_codegen_core) (1.24.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programs\\python\\lib\\site-packages (from qualia_codegen_core) (3.1.3)\n",
      "Requirement already satisfied: typing_extensions in c:\\programs\\python\\lib\\site-packages (from qualia_codegen_core) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programs\\python\\lib\\site-packages (from jinja2->qualia_codegen_core) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "%pip install qualia_codegen_core\n",
    "import qualia_codegen_core\n",
    "from qualia_codegen_core.graph.KerasModelGraph import KerasModelGraph\n",
    "from qualia_codegen_core.graph.Quantization import Quantization\n",
    "from qualia_codegen_core.graph.RoundMode import RoundMode\n",
    "\n",
    "from importlib.resources import files\n",
    "main_path = str((files('qualia_codegen_core.examples')/'Linux'/'main.cpp').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "798834e7-7812-4a75-b30f-a04084e87fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                                           | Layer                                            | Outputs                                          | Input shape                                      | Output shape                                    \n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                                 | conv2d_input                                     | conv2d                                           | (1, 224, 224, 3)                                 | ((1, 224, 224, 3),)                             \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv2d_input                                     | conv2d                                           | max_pooling2d                                    | (1, 224, 224, 3)                                 | ((1, 222, 222, 32),)                            \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv2d                                           | max_pooling2d                                    | conv2d_1                                         | (1, 222, 222, 32)                                | ((1, 111, 111, 32),)                            \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling2d                                    | conv2d_1                                         | max_pooling2d_1                                  | (1, 111, 111, 32)                                | ((1, 109, 109, 64),)                            \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv2d_1                                         | max_pooling2d_1                                  | conv2d_2                                         | (1, 109, 109, 64)                                | ((1, 54, 54, 64),)                              \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling2d_1                                  | conv2d_2                                         | max_pooling2d_2                                  | (1, 54, 54, 64)                                  | ((1, 52, 52, 128),)                             \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv2d_2                                         | max_pooling2d_2                                  | flatten_1                                        | (1, 52, 52, 128)                                 | ((1, 26, 26, 128),)                             \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling2d_2                                  | flatten_1                                        | dense_1                                          | (1, 26, 26, 128)                                 | ((1, 86528),)                                   \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "flatten_1                                        | dense_1                                          | dropout                                          | (1, 86528)                                       | ((1, 512),)                                     \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "dense_1                                          | dropout                                          | dense_2                                          | (1, 512)                                         | ((1, 512),)                                     \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "dropout                                          | dense_2                                          |                                                  | (1, 512)                                         | ((1, 10),)                                      \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelgraph = KerasModelGraph(model).convert()\n",
    "print(modelgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58598a68-b55b-4d6a-8a27-f6a2890d98c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n",
      "Softmax activation must be used as a standalone layer, not combined to another layer (TDenseLayer)\n",
      "ModelGraph validation failed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m float_res \u001b[38;5;241m=\u001b[39m qualia_codegen_core\u001b[38;5;241m.\u001b[39mConverter(output_path\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_output_floating\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mconvert_model(float_modelgraph)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_model_floating.h\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloat_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not None"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "float_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for float32\n",
    "for node in float_modelgraph.nodes:\n",
    "    # No scale factor if not fixed-point quantization on integers\n",
    "    node.q = Quantization(\n",
    "            number_type=float,\n",
    "            width=32,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=0,\n",
    "            output_scale_factor=0,\n",
    "            weights_round_mode=RoundMode.NONE,\n",
    "            output_round_mode=RoundMode.NONE,\n",
    "            )\n",
    "\n",
    "float_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_floating')).convert_model(float_modelgraph)\n",
    "\n",
    "with open('gsc_model_floating.h', 'w') as f:\n",
    "    f.write(float_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ad26539-5815-4c9a-acf6-4816691a45d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cc1plus.exe: fatal error: gsc_output_floating/model.c: No such file or directory\n",
      "compilation terminated.\n",
      "<command-line>: fatal error: gsc_output_floating/include/defines.h: No such file or directory\n",
      "compilation terminated.\n",
      "'.' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_floating -include gsc_output_floating/include/defines.h -Igsc_output_floating/include gsc_output_floating/model.c {main_path}\n",
    "!./gsc_floating x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c4d2447-f5b5-42c6-86b7-1fc192c6b3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n",
      "Softmax activation must be used as a standalone layer, not combined to another layer (TDenseLayer)\n",
      "ModelGraph validation failed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m fixed_res \u001b[38;5;241m=\u001b[39m qualia_codegen_core\u001b[38;5;241m.\u001b[39mConverter(output_path\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_output_fixed\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mconvert_model(fixed_modelgraph)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgsc_model_fixed.h\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not None"
     ]
    }
   ],
   "source": [
    "fixed_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for int16 Q9.7\n",
    "for node in fixed_modelgraph.nodes:\n",
    "    node.q = Quantization(\n",
    "            number_type=int,\n",
    "            width=16,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=7,\n",
    "            output_scale_factor=7,\n",
    "            weights_round_mode=RoundMode.FLOOR,\n",
    "            output_round_mode=RoundMode.FLOOR,\n",
    "            )\n",
    "\n",
    "fixed_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_fixed')).convert_model(fixed_modelgraph)\n",
    "\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(fixed_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68ebd301-5db5-4457-a939-430308b4f189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cc1plus.exe: fatal error: gsc_output_fixed/model.c: No such file or directory\n",
      "compilation terminated.\n",
      "<command-line>: fatal error: gsc_output_fixed/include/defines.h: No such file or directory\n",
      "compilation terminated.\n",
      "'.' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_fixed -include gsc_output_fixed/include/defines.h -Igsc_output_fixed/include gsc_output_fixed/model.c {main_path}\n",
    "!./gsc_fixed x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c9e7e-4487-4373-ac6c-8bd3a447e1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
